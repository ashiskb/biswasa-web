---
title: "CSCI-4800/5800: AI with Reinforcement Learning"
collection: teaching
type: "Graduate course"
permalink: /teaching/2023-spring-RL-4800-5800/
venue: "SCIENCE-1067 (Tue only) + Online async"
date: 2023-01-15
toc: true
location: "Denver, CO, USA."
---

We now live in an era of Artificial Intelligence (AI) where we rely on responses as well as actions by numerous autonomous systems that are crisscrossed in our daily lives. These systems are powered by AI that learn to provide us with reasonable answers for us with respect to our respective perspectives. Reinforcement learning is one of the most advanced and powerful way of developing such systems and are very much in line with the learning paradigms used to make us knowledgeable since our childhood, which is to learn from our mistakes. In this course, students are going to get a solid foundation in the field of reinforcement learning, learn the core challenges, and ideas to bring in newer approaches to make the systems robust, and more humanoid, and better to some degree. Through a combination of lectures, programming assignments students are expected to receive a hands-on-experience in exploring this field effectively. In addition, through the final project in this course, students will advance their understanding of reinforcement learning paradigm and are going to be able to design, develop and demonstrate by the end of the semester smart competitive players in video games, autonomous chatbots, autonomous vehicle control systems, early detection of malicious activities in the communication networks in the field of cybersecurity, and so on.

Course objectives
======
By the end of the course you are expected to gain the following skills:

1. learn key ideas and algorithms of reinforcement learning -- a more powerful paradigm in the field of machine learning.
2. be able to understand where reinforcement learning algorithms fit to solve problems.
3. apply reinforcement learning algorithms to solve various practical problems.


Prerequisites
======
1. The `graduate standing`.

Recommended Textbooks
======
1. Winder, Phil (2020). Reinforcement learning -- industrial application of intelligent agents. O'Reilly Media. [[ official-web ]](https://rl-book.com)
2. Sutton Richard S. and Barto Andrew G. (2018) Reinforcement Learning: An Introduction. MIT Press [[ official-web]](http://www.incompleteideas.net/book/the-book.html), [ [PDF]](http://www.incompleteideas.net/book/RLbook2020.pdf)

Topics planned to be covered
======
1. Introduction to Reinforcement Learning
2. Introduction to Amazon AWS Deepracer
3. Policy based and value based learning algorithms
4. Monte-carlo methods to learn
5. Deep Learning introduction
6. Comparative analysis of 3 reinforcement learning paradigms: DP, MC, TD
7. The SARSA algorithm
8. A non-tabular (e.g., approximation) approach in RL
9. Continous action space
10. Actor-critic
11. Value function approximation
12. On Temporal differende learning -- TD(Lamba)

Schedule
=======

### Week 1

*Total watch hour: x hours y minutes and z seconds*
1. Introduction to Reinforcement Learning
2. Course Logistics & expectations
3. Reinforcement Learning applications (a higher-level overview)
4. Introduction to Reinforcement Learning with OpenAI-Gym [ [Notebook/Slide](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/01_openai-gym-intro.ipynb) ] [ [Github-Repo](https://github.com/ashiskb/RL-workspace.git) ] [ [Video-Recording](https://youtu.be/ZQp4mzln41U), 37:11 ] 
5. Working with OpenAI-Gym environments [Notebook/Slides: [ALE/Breakout](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/02_openai-gym-ALE-Breakout-v5.ipynb), [Blackjack](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/03_openai-gym-Blackjack-v1.ipynb), [CarRacing](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/04_openai-gym-CarRacing-v2.ipynb), [ALE/Pong](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/05_openai-gym-ALE-Pong-v5.ipynb), [ALE/Riverraid](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/06_openai-gym-ALE_Riverraid-v5.ipynb) ][ [Github-Repo](https://github.com/ashiskb/RL-workspace.git) ] [ [Video-Recording](https://youtu.be/q3_USI62n8k), 16:00 ]
6. Making of an Intelligent CartPole agent [Notebook/Slides: [Random CartPole Agent](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/07_openai-gym-CartPole-v0-Random.ipynb), [Q-learning CartPole Agent](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/08_openai-gym-CartPole-v0-QLearning.ipynb)][ [Github-Repo](https://github.com/ashiskb/RL-workspace.git) ] [ [Video-Recording](https://youtu.be/NRI_d6TAA9U), 48:27]
7. Non-gym environment and Reinforcement learning from scratch [Notebook/Slides: [Goal-vs-Hole-v0](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/09_non-gym-RL-intro-1.ipynb), [Goal-vs-Hole-v1](https://github.com/ashiskb/RL-workspace/blob/master/notebooks/10_non-gym-RL-intro-2.ipynb)][ [Github-Repo](https://github.com/ashiskb/RL-workspace.git) ] [ [Video-Recording](https://youtu.be/5-YoTy_1msE), 35:09 ]

### Week 2

*Total watch hour: x hours y minutes and z seconds*
1. Multi-bandit problem [Notebook+slides: [ashiskb@github link](https://github.com/ashiskb/RL-workspace/blob/master/sb-workspace/02_multiarmed-bandit.ipynb)] [[A supporting video lecture by Connor Shorten](https://youtu.be/9LhNHK1ULxs)] [Reference study: SB-2]
2. Markov Decision Process, Dynamic Programming for action selection intro [ [Slides](https://drive.google.com/file/d/1ZWYhL0u9raTo47c3YocA_U33mZx_Gp4J/view?usp=share_link)] [[Video-Lecture by Dr. B](https://youtu.be/P5KvM9X6d4Y)] [Reference study: SB-3, 4]


### Week 3

*Total watch hour: x hours y minutes and z seconds*
1. More into Dynamic Programming, MDP 
2. Temporal Difference Learning
3. Q-learning
4. n-Step algorithms


### Week 4

*Total watch hour: x hours y minutes and z seconds*
1. Monte-Carlo Methods

### Week 5

*Total watch hour: x hours y minutes and z seconds*
1. Deep Q-networks


### Week 6

*Total watch hour: x hours y minutes and z seconds*
1. Policy Gradient Methods

### Week 7

*Total watch hour: x hours y minutes and z seconds*
1. Beyond Policy Gradients


### Week 8

* Reserved for ``midterm``


### Week 9

*Total watch hour: x hours y minutes and z seconds*
1. Reinforcement Learning in action


### Week 10


* SPRING BREAK!!! No classes scheduled.


### Week 11

*Total watch hour: x hours y minutes and z seconds*
1. Reinforcement Learning in action (part 2)


### Week 12

*Total watch hour: x hours y minutes and z seconds*
1. Reinforcement Learning in action (part 3)

    


### Week 13


*Total watch hour: x hours y minutes and z seconds*
* Project live demo week & feedback




### Week 14


*Total watch hour: x hours y minutes and z seconds*

* Project live demo week (addressing the feedbacks)



### Week 15

1. Reserved to wrapping-up the course.


### Week 16

1. Reserved for ``final exam``